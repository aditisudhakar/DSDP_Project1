{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travel and Tourism Reform Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "\n",
    "**Dataframes:** \n",
    "- df_qcontcust_2009_2019 -> contains data on all years between 2009 - 2019\n",
    "- df_qcontcust_2009, df_qcontcust_2010, ... to df_qcontcust_2019 -> filtered from df_qcontcust_2009_2019 for each year\n",
    "- df_qcontcust_2022 -> contains data for 2022 \n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import json\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "\n",
    "import scipy.stats as ss\n",
    "from scipy.stats import kruskal\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qcontcust_2009_2019 = pd.read_csv(\"C:\\\\Users\\\\medasud\\\\Downloads\\\\2013-UKDA-7380-tab\\\\tab\\\\qcontcust_2009_2019.tab\", delimiter='\\t')\n",
    "#filtering the dataset into different years\n",
    "df_qcontcust_2009 = df_qcontcust_2009_2019[df_qcontcust_2009_2019['Year'] == 2009]\n",
    "df_qcontcust_2010 = df_qcontcust_2009_2019[df_qcontcust_2009_2019['Year'] == 2010]\n",
    "df_qcontcust_2011 = df_qcontcust_2009_2019[df_qcontcust_2009_2019['Year'] == 2011]\n",
    "df_qcontcust_2012 = df_qcontcust_2009_2019[df_qcontcust_2009_2019['Year'] == 2012]\n",
    "df_qcontcust_2013 = df_qcontcust_2009_2019[df_qcontcust_2009_2019['Year'] == 2013]\n",
    "df_qcontcust_2014 = df_qcontcust_2009_2019[df_qcontcust_2009_2019['Year'] == 2014]\n",
    "df_qcontcust_2015 = df_qcontcust_2009_2019[df_qcontcust_2009_2019['Year'] == 2015]\n",
    "df_qcontcust_2016 = df_qcontcust_2009_2019[df_qcontcust_2009_2019['Year'] == 2016]\n",
    "df_qcontcust_2017 = df_qcontcust_2009_2019[df_qcontcust_2009_2019['Year'] == 2017]\n",
    "df_qcontcust_2018 = df_qcontcust_2009_2019[df_qcontcust_2009_2019['Year'] == 2018]\n",
    "df_qcontcust_2019 = df_qcontcust_2009_2019[df_qcontcust_2009_2019['Year'] == 2019]\n",
    "df_qcontcust_2022 = pd.read_csv(\"C:\\\\Users\\\\medasud\\\\Downloads\\\\2022-UKDA-9122-tab\\\\tab\\\\qcontcust2022.tab\", delimiter='\\t')\n",
    "\n",
    "\n",
    "df_qreg_2013 = pd.read_csv(\"C:\\\\Users\\\\medasud\\\\Downloads\\\\2013-UKDA-7380-tab\\\\tab\\\\qreg_2013.tab\", delimiter='\\t')\n",
    "df_qreg_2014 = pd.read_csv(\"C:\\\\Users\\\\medasud\\\\Downloads\\\\2014-UKDA-7534-tab\\\\tab\\\\qreg_2014.tab\", delimiter='\\t')\n",
    "df_qreg_2015 = pd.read_csv(\"C:\\\\Users\\\\medasud\\\\Downloads\\\\2015-UKDA-7754-tab\\\\tab\\\\qreg_2015.tab\", delimiter='\\t')\n",
    "df_qreg_2016 = pd.read_csv(\"C:\\\\Users\\\\medasud\\\\Downloads\\\\2016-UKDA-8016-tab\\\\tab\\\\qreg_2016.tab\", delimiter='\\t')\n",
    "df_qreg_2017 = pd.read_csv(\"C:\\\\Users\\\\medasud\\\\Downloads\\\\2017-UKDA-8286-tab\\\\tab\\\\qreg_2017.tab\", delimiter='\\t')\n",
    "df_qreg_2018 = pd.read_csv(\"C:\\\\Users\\\\medasud\\\\Downloads\\\\2018-UKDA-8468-tab\\\\tab\\\\qreg_2018.tab\", delimiter='\\t')\n",
    "df_qreg_2019 = pd.read_csv(\"C:\\\\Users\\\\medasud\\\\Downloads\\\\2019-UKDA-8575-tab\\\\tab\\\\qreg_2019.tab\", delimiter='\\t')\n",
    "df_qreg_2022 = pd.read_csv(\"C:\\\\Users\\\\medasud\\\\Downloads\\\\2022-UKDA-9122-tab\\\\tab\\\\qreg_2022.tab\", delimiter='\\t')\n",
    "#qreg is not available for 2009-2012\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Serial', 'Year', 'Quarter', 'Month', 'Flow', 'res', 'cty', 'nation',\n",
       "       'purp', 'Purpose', 'county', 'Age', 'Sex', 'ukport', 'Nationality',\n",
       "       'Residence', 'CountryVisit', 'country', 'port1', 'port2', 'AirPortCode',\n",
       "       'ChangeCode', 'UKLEG', 'OVLEG', 'DIRECTLEG', 'origdest', 'carrier1',\n",
       "       'transfer', 'flprefix', 'shuttnum', 'bustick', 'flightyp', 'Vehicle',\n",
       "       'vehno', 'persons', 'indtouk', 'ind', 'itcost', 'ninfare', 'ninfarek',\n",
       "       'fare', 'farek', 'expppv', 'netexp', 'mtrans', 'highexp', 'haul',\n",
       "       'seaind', 'shift', 'quality', 'stay', 'spend', 'spendk', 'TandTSI',\n",
       "       'FinalWeight', 'DayOfWeek', 'shiftWeight', 'NonRespWeight',\n",
       "       'minimumsWeight', 'sampTrafficWeight', 'unsampTrafficWeight',\n",
       "       'Old_imbalanceWeight', 'shiftWeightgrp', 'NRWeightgrp', 'minsWeightgrp',\n",
       "       'sampTrafficWtgrp', 'UnsampwgtPortgrp', 'UnsampwtRegiongrp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qcontcust_2017.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of columns to drop\n",
    "#these variables will not be used in this project\n",
    "columns_to_drop = ['UKLEG', 'OVLEG', 'DIRECTLEG', 'shiftWeight', 'NonRespWeight', 'minimumsWeight', \n",
    "                   'sampTrafficWeight', 'flprefix', 'shuttnum', 'bustick', 'indtouk', 'ind', \n",
    "                   'itcost', 'ninfare', 'ninfarek', 'fare', 'farek', 'mtrans', 'highexp', 'haul',\n",
    "                   'seaind', 'TandTSI', 'unsampTrafficWeight', 'Old_imbalanceWeight', 'shiftWeightgrp',\n",
    "                   'NRWeightgrp', 'minsWeightgrp', 'sampTrafficWtgrp', 'UnsampwgtPortgrp',\n",
    "                   'UnsampwtRegiongrp']\n",
    "\n",
    "dataframes = [df_qcontcust_2009, df_qcontcust_2010, df_qcontcust_2011, df_qcontcust_2012,\n",
    "              df_qcontcust_2013, df_qcontcust_2014, df_qcontcust_2015, df_qcontcust_2016,\n",
    "              df_qcontcust_2017, df_qcontcust_2018, df_qcontcust_2019]\n",
    "#iterate over the list of dataframes and drop the columns\n",
    "for df in dataframes:\n",
    "    df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Serial', 'Year', 'Quarter', 'Month', 'Flow', 'res', 'cty', 'nation',\n",
       "       'purp', 'Purpose', 'county', 'Age', 'Sex', 'ukport', 'Nationality',\n",
       "       'Residence', 'CountryVisit', 'country', 'port1', 'port2', 'AirPortCode',\n",
       "       'ChangeCode', 'UKLEG', 'OVLEG', 'DIRECTLEG', 'origdest', 'carrier1',\n",
       "       'transfer', 'flprefix', 'shuttnum', 'bustick', 'flightyp', 'Vehicle',\n",
       "       'vehno', 'persons', 'indtouk', 'ind', 'itcost', 'ninfare', 'ninfarek',\n",
       "       'Fare', 'expppv', 'NetExp', 'haul', 'seaind', 'shift', 'Quality',\n",
       "       'Stay', 'Spend', 'TANDTSI', 'FinalWeight', 'IntDate', 'shiftWeight',\n",
       "       'NonRespWeight', 'minimumsWeight', 'sampTrafficWeight',\n",
       "       'unsampTrafficWeight', 'old_ImbalanceWeight', 'shiftWeightgrp',\n",
       "       'NRWeightgrp', 'minsWeightgrp', 'sampTrafficWtgrp', 'UnsampwgtPortgrp',\n",
       "       'UnsampwtRegiongrp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qcontcust_2022.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of columns to drop\n",
    "columns_to_drop = ['shiftWeight', 'NonRespWeight', 'minimumsWeight', 'sampTrafficWeight',\n",
    "                   'unsampTrafficWeight', 'old_ImbalanceWeight', 'shiftWeightgrp',\n",
    "                   'NRWeightgrp', 'minsWeightgrp', 'sampTrafficWtgrp', 'UnsampwgtPortgrp',\n",
    "                   'UnsampwtRegiongrp', 'UKLEG', 'OVLEG', 'DIRECTLEG','flprefix', 'shuttnum', \n",
    "                   'bustick', 'indtouk', 'ind', 'itcost', 'ninfare', 'ninfarek', 'seaind', \n",
    "                   'TANDTSI','haul']\n",
    "\n",
    "#column names are different for the other dataframes\n",
    "df_qcontcust_2022.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating New Variables from Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary for flow\n",
    "flow_dict = {\n",
    "    1.0: \"Air Departure Foreign\",\n",
    "    2.0: \"Air Departure UK\",\n",
    "    3.0: \"Air Arrival Foreign\",\n",
    "    4.0: \"Air Arrival UK\",\n",
    "    5.0: \"Sea Departure Foreign\",\n",
    "    6.0: \"Sea Departure UK\",\n",
    "    7.0: \"Sea Arrival Foreign\",\n",
    "    8.0: \"Sea Arrival UK\"\n",
    "}\n",
    "\n",
    "#function to create Flow_Label column for all years\n",
    "\n",
    "def create_flow_label_column(df):\n",
    "    \"\"\"\n",
    "    This function creates a new column FLow_Label which is derived from the column Flow\n",
    "    and an external data dictionary mapping the integer/float values in Flow to their respective \n",
    "    values. This is for all years.\n",
    "\n",
    "    Parameters:\n",
    "    param1 : the dataframe being manipulated\n",
    " \n",
    "    Returns:\n",
    "    no return value. When the function is called, the new column is created.\n",
    "    \"\"\"\n",
    "    #fill missing values in Purpose column with -1\n",
    "    df['Flow'].replace(' ', np.nan, inplace=True)\n",
    "    df['Flow'].fillna(-1, inplace=True)\n",
    "    df['Flow'] = df['Flow'].astype(float)\n",
    "    df['Flow'].replace('-1', np.nan, inplace=True)\n",
    "    \n",
    "    df['Flow_Label'] = df['Flow'].map(flow_dict)\n",
    "\n",
    "#call this function for df_qcontcust of each year\n",
    "dataframes = [df_qcontcust_2009, df_qcontcust_2010, df_qcontcust_2011, df_qcontcust_2012,\n",
    "              df_qcontcust_2013, df_qcontcust_2014, df_qcontcust_2015, df_qcontcust_2016,\n",
    "              df_qcontcust_2017, df_qcontcust_2018, df_qcontcust_2019, df_qcontcust_2022]\n",
    "\n",
    "#iterate over the list of dataframes and apply the function\n",
    "for df in dataframes:\n",
    "    create_flow_label_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flow_Label\n",
       "Air Departure UK         103740\n",
       "Air Arrival UK            55851\n",
       "Air Arrival Foreign       54274\n",
       "Air Departure Foreign     41071\n",
       "Sea Departure UK          13884\n",
       "Sea Arrival Foreign       11296\n",
       "Sea Arrival UK             9825\n",
       "Sea Departure Foreign      9146\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qcontcust_2015['Flow_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column Purpose_Label for years 2009-19\n",
    "\n",
    "#load the mapping from the JSON file\n",
    "file_path = \"C:\\\\Users\\\\medasud\\\\Documents\\\\Project1\\\\Purpose_value_map_0919.json\"\n",
    "with open(file_path, 'r') as json_file:\n",
    "    purpose_mapping_0919 = json.load(json_file)\n",
    "\n",
    "#function to create Purpose_Label column\n",
    "def create_purpose_column_0919(df, mapping):\n",
    "    \"\"\"\n",
    "    This function creates a new column Purpose_Label which is derived from the column Purpose\n",
    "    and an external data dictionary mapping the integer/float values in Purpose to their respective \n",
    "    purposes. This is for the years 2009-2019 only.\n",
    "\n",
    "    Parameters:\n",
    "    param1 : the dataframe being manipulated\n",
    "    param2 : the mapping from the json file\n",
    "\n",
    "    Returns:\n",
    "    no return value. When the function is called, the new column is created.\n",
    "    \"\"\"\n",
    "    df['Purpose'].replace(' ', pd.NA, inplace=True)\n",
    "    df['Purpose'].fillna(-1, inplace=True)\n",
    "    df['Purpose'] = df['Purpose'].astype(float)\n",
    "    df['Purpose'] = df['Purpose'].astype(str)\n",
    "    \n",
    "    # Create a new column \"Purpose_Label\" by mapping the values\n",
    "    df['Purpose_Label'] = df['Purpose'].map(mapping)\n",
    "    df['Purpose'] = df['Purpose'].astype(float)\n",
    "    \n",
    "#call this function for df_qcontcust of each year\n",
    "dataframes = [df_qcontcust_2009, df_qcontcust_2010, df_qcontcust_2011, df_qcontcust_2012,\n",
    "              df_qcontcust_2013, df_qcontcust_2014, df_qcontcust_2015, df_qcontcust_2016,\n",
    "              df_qcontcust_2017, df_qcontcust_2018, df_qcontcust_2019]\n",
    "\n",
    "#iterate over the list of dataframes and apply the function\n",
    "for df in dataframes:\n",
    "    create_purpose_column_0919(df, purpose_mapping_0919)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column Purpose_Label for years 2022\n",
    "\n",
    "#load the mapping from the JSON file\n",
    "file_path = \"C:\\\\Users\\\\medasud\\\\Documents\\\\Project1\\\\Purpose_value_map_22.json\"\n",
    "with open(file_path, 'r') as json_file:\n",
    "    purpose_mapping_22 = json.load(json_file)\n",
    "    \n",
    "#function to create Purpose_Label column\n",
    "def create_purpose_column_22(df, mapping):\n",
    "    \"\"\"\n",
    "    This function creates a new column Purpose_Label which is derived from the column Purpose\n",
    "    and an external data dictionary mapping the integer/float values in Purpose to their respective \n",
    "    purposes. This is for the years 2022 only as the Purpose codes are different for this year.\n",
    "    Purpose codes for subsequent years are likely to remain the same, and in that case, this function\n",
    "    can be reused.\n",
    "\n",
    "    Parameters:\n",
    "    param1 : the dataframe being manipulated\n",
    "    param2 : the mapping from the json file\n",
    "\n",
    "    Returns:\n",
    "    no return value. When the function is called, the new column is created.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['Purpose'].replace(' ', pd.NA, inplace=True)\n",
    "    df['Purpose'].fillna(-1, inplace=True)\n",
    "    df['Purpose'] = df['Purpose'].astype(float)\n",
    "    df['Purpose'] = df['Purpose'].astype(str)\n",
    "    \n",
    "    # Create a new column \"Purpose_Label\" by mapping the values\n",
    "    df['Purpose_Label'] = df['Purpose'].map(mapping)\n",
    "    df['Purpose'] = df['Purpose'].astype(float)\n",
    "    \n",
    "#call the function\n",
    "create_purpose_column_22(df_qcontcust_2022, purpose_mapping_22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Purpose_Label\n",
       "Holiday/pleasure                                               51586\n",
       "Visit family (priority)                                        29972\n",
       "Business; Work                                                 11315\n",
       "Visit friends                                                   4723\n",
       "Same day transit                                                2970\n",
       "Overnight transit                                               1372\n",
       "OTHER                                                           1098\n",
       "Watch sport                                                     1043\n",
       "Play amateur sport                                               645\n",
       "Definite job to go to                                            528\n",
       "Medical Treatment                                                476\n",
       "Cruise 0-2 nights ashore - For                                   242\n",
       "International commuter                                           216\n",
       "Military or embassy (serving on duty)                            178\n",
       "First or Foundation Degree                                       177\n",
       "Higher or Postgraduate Degree                                    160\n",
       "Accompany another traveller                                      149\n",
       "Cruise 0-2 nights ashore - UK                                    128\n",
       "Merchant navy (joining or leaving ship)                          119\n",
       "Getting married                                                  114\n",
       "English language course (not degree level)                       104\n",
       "Airline crew (positioning)                                        91\n",
       "Personal shopping                                                 87\n",
       "Embassy Personel                                                  81\n",
       "Formal Course                                                     53\n",
       "Joining another traveller                                         33\n",
       "Professional qualification                                        29\n",
       "Secondary education                                               26\n",
       "Looking for work                                                  19\n",
       "Other Course Below Degree Level & Above Secondary Education       16\n",
       "Au Pair                                                            8\n",
       "Unacc schoolchild (16 or under, school to parents)                 4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qcontcust_2022['Purpose_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Purpose_Label\n",
       "Holiday/pleasure                                      50472\n",
       "Visit family (priority)                               22423\n",
       "Business; Work                                        18709\n",
       "Visit friends                                          4677\n",
       "Same day transit                                       3180\n",
       "Overnight transit                                      1331\n",
       "Play amateur sport                                     1157\n",
       "OTHER                                                  1151\n",
       "Watch sport                                            1060\n",
       "Personal shopping                                       743\n",
       "Other formal study                                      654\n",
       "Cruise 0-2 nights ashore - For                          408\n",
       "Definite job to go to                                   345\n",
       "Accompany / join                                        242\n",
       "Medical treatment                                       211\n",
       "Cruise 0-2 nights ashore - UK                           209\n",
       "Military (serving on duty)                              203\n",
       "Looking for work                                        145\n",
       "Merchant navy (joining or leaving ship)                 120\n",
       "Getting married                                         116\n",
       "International commuter                                  102\n",
       "Airline crew (positioning)                               68\n",
       "Au Pair                                                  18\n",
       "Unacc schoolchild (16 or under, school to parents)       17\n",
       "Conference 20+ people                                     5\n",
       "Visit trade fair                                          5\n",
       "Immigrating/Emigrating                                    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qcontcust_2013['Purpose_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column Nationality_Label for years 2009-19\n",
    "\n",
    "#load the mapping from the JSON file\n",
    "file_path = \"C:\\\\Users\\\\medasud\\\\Documents\\\\Project1\\\\Nationality_value_map_0919.json\"\n",
    "with open(file_path, 'r') as json_file:\n",
    "    nationality_mapping_0919 = json.load(json_file)\n",
    "\n",
    "#function to create Nationality_Label column for 2009-2019\n",
    "def create_nationality_label_column_0919(df):\n",
    "    \"\"\"\n",
    "    This function creates a new column Nationality_Label which is derived from the column Nationality\n",
    "    and an external data dictionary mapping the integer/float values in Nationality to their respective \n",
    "    purposes. This is for the years 2009-2019 only.\n",
    "\n",
    "    Parameters:\n",
    "    param1 : the dataframe being manipulated.\n",
    "\n",
    "    Returns:\n",
    "    return value. When the function is called, the new column is created.\n",
    "    \"\"\"\n",
    "    df['Nationality'].replace(' ', np.nan, inplace=True)\n",
    "    df['Nationality'].fillna(-1, inplace=True)\n",
    "    #changing to the datatype to str to facilitate mapping as the JSON file has the key as type string by default\n",
    "    df['Nationality'] = df['Nationality'].astype(str)\n",
    "    \n",
    "    #create a new column Nationality_Label by mapping the values\n",
    "    df['Nationality_Label'] = df['Nationality'].map(nationality_mapping_0919)\n",
    "    df['Nationality_Label'].fillna((\"Unknown\"), inplace=True)\n",
    "    df['Nationality'] = df['Nationality'].astype(float) \n",
    "\n",
    "#call this function for df_qcontcust of each year\n",
    "dataframes = [df_qcontcust_2009, df_qcontcust_2010, df_qcontcust_2011, df_qcontcust_2012,\n",
    "              df_qcontcust_2013, df_qcontcust_2014, df_qcontcust_2015, df_qcontcust_2016,\n",
    "              df_qcontcust_2017, df_qcontcust_2018, df_qcontcust_2019]\n",
    "\n",
    "#iterate over the list of dataframes and apply the function for 2009-2019\n",
    "for df in dataframes:\n",
    "    create_nationality_label_column_0919(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column Nationality_Label for years 2022 onwards\n",
    "\n",
    "#load the mapping from the JSON file\n",
    "file_path = \"C:\\\\Users\\\\medasud\\\\Documents\\\\Project1\\\\Nationality_value_map_22.json\"\n",
    "with open(file_path, 'r') as json_file:\n",
    "    nationality_mapping_22 = json.load(json_file)\n",
    "    \n",
    "#function to create Nationality_Label column for 2022 onwards\n",
    "def create_nationality_label_column_22(df):\n",
    "    \"\"\"\n",
    "    This function creates a new column Nationality_Label which is derived from the column Nationality\n",
    "    and an external data dictionary mapping the integer/float values in Nationality to their respective \n",
    "    purposes for the year 2022 and onwards.\n",
    "    \n",
    "    Parameters:\n",
    "    param1 : the dataframe being manipulated.\n",
    "\n",
    "    Returns:\n",
    "    no return value. When the function is called, the new column is created.\n",
    "    \"\"\"\n",
    "    df['Nationality'].replace(' ', np.nan, inplace=True)\n",
    "    df['Nationality'].fillna(-1, inplace=True)\n",
    "    #changing to the datatype to str to facilitate mapping as the JSON file has the key as type string by default\n",
    "    df['Nationality'] = df['Nationality'].astype(str)\n",
    "    \n",
    "    #create a new column Nationality_Label by mapping the values\n",
    "    df['Nationality_Label'] = df['Nationality'].map(nationality_mapping_22)\n",
    "    df['Nationality_Label'].fillna((\"Unknown\"), inplace=True)\n",
    "    df['Nationality'] = df['Nationality'].astype(float) \n",
    "\n",
    "#call this function for df_qcontcust_2022\n",
    "for df in dataframes:\n",
    "    create_nationality_label_column_22(df_qcontcust_2022)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nationality_Label\n",
       "UK                      157672\n",
       "USA                      17817\n",
       "Irish Republic            9862\n",
       "France/Corsica            8407\n",
       "Poland                    7766\n",
       "                         ...  \n",
       "Papua New Guinea             1\n",
       "Surinam/Dutch Guiana         1\n",
       "Gabon                        1\n",
       "Bhutan                       1\n",
       "Burkina Faso                 1\n",
       "Name: count, Length: 211, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qcontcust_2022['Nationality_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nationality_Label\n",
       "UK/United Kingdom               137118\n",
       "USA/United States of America     14062\n",
       "France                            8991\n",
       "Poland                            8421\n",
       "Germany                           7605\n",
       "                                 ...  \n",
       "Korea, North                         1\n",
       "San Marino                           1\n",
       "Lesotho                              1\n",
       "Guinea - Bissau                      1\n",
       "Cape Verde Islands                   1\n",
       "Name: count, Length: 198, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qcontcust_2017['Nationality_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create Stay_Category\n",
    "\n",
    "def create_stay_category_column(df):\n",
    "    \"\"\"\n",
    "    This function creates a new column Stay_Category which is derived from the column Stay, a numeric continuous variable.\n",
    "    The Stay_Category column is used to convert Stay into factor levels that can later be used for model training purposes,\n",
    "    as most of the variables in this dataset are also categorical.\n",
    "\n",
    "    Parameters:\n",
    "    param1 : the dataframe being manipulated.\n",
    "\n",
    "    Returns:\n",
    "    no return value. When the function is called, the new column is created.\n",
    "    \"\"\"\n",
    "    \n",
    "    #the variable names are different across the dataframes so we accomodate this\n",
    "    stay_column_name = next((col for col in ['Stay', 'stay'] if col in df.columns), None)\n",
    "    if stay_column_name is not None:\n",
    "        df[stay_column_name].replace(' ', np.nan, inplace=True)\n",
    "        df[stay_column_name] = pd.to_numeric(df[stay_column_name], errors='coerce')\n",
    "    \n",
    "    #we only want to consider stays for less than a year\n",
    "    #removing outliers in Stay duration, only retaining stays that are less than a year\n",
    "    df[stay_column_name] = df[stay_column_name].astype(float)\n",
    "    df[stay_column_name] = df[stay_column_name][df[stay_column_name] <= 365]\n",
    "    intervals = [1, 3, 13, 27, 90, 180, 365]\n",
    "    labels = ['1-3 days', '4-13 days', '14-27 days', '1-3 months', '3-6 months', '6-12 months']\n",
    "    df['Stay_Category'] = pd.cut(df[stay_column_name], bins=intervals, labels=labels)\n",
    "    \n",
    "#call this function for df_qcontcust of each year\n",
    "dataframes = [df_qcontcust_2009, df_qcontcust_2010, df_qcontcust_2011, df_qcontcust_2012,\n",
    "              df_qcontcust_2013, df_qcontcust_2014, df_qcontcust_2015, df_qcontcust_2016,\n",
    "              df_qcontcust_2017, df_qcontcust_2018, df_qcontcust_2019, df_qcontcust_2022]\n",
    "\n",
    "#iterate over the list of dataframes and apply the function for all years\n",
    "for df in dataframes:\n",
    "    create_stay_category_column(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create Spend_Category\n",
    "\n",
    "def create_spend_category_column(df):\n",
    "    \"\"\"\n",
    "    This function creates a new column Spend_Category which is derived from the column Spend, a numeric continuous variable.\n",
    "    The Spend_Category column is used to convert Spend into factor levels that can later be used for model training purposes,\n",
    "    as most of the variables in this dataset are also categorical.\n",
    "\n",
    "    Parameters:\n",
    "    param1 : the dataframe being manipulated.\n",
    "\n",
    "    Returns:\n",
    "    no return value. When the function is called, the new column is created.\n",
    "    \"\"\"\n",
    "    #the variable names are different across the dataframes so we accommodate this\n",
    "    spend_column_name = next((col for col in ['Spend', 'spend'] if col in df.columns), None)\n",
    "    if spend_column_name is not None:\n",
    "        df[spend_column_name].replace(' ', np.nan, inplace=True)\n",
    "        df[spend_column_name] = pd.to_numeric(df[spend_column_name], errors='coerce')\n",
    "\n",
    "        #we only want to consider expenditure less than 10k as more than that would be outliers\n",
    "        df[spend_column_name] = df[spend_column_name].astype(float)\n",
    "        df[spend_column_name] = df[spend_column_name][df[spend_column_name] <= 10000]\n",
    "\n",
    "        intervals = [0, 250, 500, 1000, 5000, float('inf')]\n",
    "        labels = ['0-250 GBP', '250-500 GBP', '500-1000 GBP', '1000-5000 GBP', 'more than 5000 GBP']\n",
    "        df['Spend_Category'] = pd.cut(df[spend_column_name], bins=intervals, labels=labels)\n",
    "\n",
    "#call this function for df_qcontcust of each year\n",
    "dataframes = [df_qcontcust_2009, df_qcontcust_2010, df_qcontcust_2011, df_qcontcust_2012,\n",
    "              df_qcontcust_2013, df_qcontcust_2014, df_qcontcust_2015, df_qcontcust_2016,\n",
    "              df_qcontcust_2017, df_qcontcust_2018, df_qcontcust_2019, df_qcontcust_2022]\n",
    "\n",
    "#iterate over the list of dataframes and apply the function for all years\n",
    "for df in dataframes:\n",
    "    create_spend_category_column(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stay_Category\n",
       "4-13 days      48027\n",
       "1-3 days       22130\n",
       "14-27 days     13932\n",
       "1-3 months      4589\n",
       "3-6 months       677\n",
       "6-12 months      223\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qcontcust_2016['Stay_Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Spend_Category\n",
       "0-250 GBP             21868\n",
       "250-500 GBP           17910\n",
       "500-1000 GBP          16606\n",
       "1000-5000 GBP         11576\n",
       "more than 5000 GBP      480\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qcontcust_2018['Spend_Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#purposes of visit that we are not interested in for years\n",
    "excluded_purposes = [\"International commuter\", \"Immigrating/Emigrating\", \"Overnight transit\", \"Asylum Seeker\",\n",
    "                     \"Same day transit\", \"Military (serving on duty)\", \"Returning Home To Live\", \n",
    "                     \"Merchant navy (joining or leaving ship)\", \"Military or embassy (serving on duty)\",\n",
    "                     \"Airline crew (positioning)\", \"Coding query\", \"Looking for work\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column Broad_Purpose to catgorise the different purposes of visit into 4 main categories\n",
    "\n",
    "def create_broad_purpose_column(df):\n",
    "    \"\"\"\n",
    "    This function creates a new column Broad_Purpose which is derived from the column Purpose_Label.\n",
    "    Broad_Purpose catgorises the different purposes of visit into 4 main categories. These purposes will\n",
    "    be further filtered later in this notebook.\n",
    "    Broad_Purpose is the main variable of interest in this project.\n",
    "\n",
    "    Parameters:\n",
    "    param1 : the dataframe being manipulated.\n",
    "\n",
    "    Returns:\n",
    "    no return value. When the function is called, the new column is created.\n",
    "    \"\"\"\n",
    "    #define the conditions for the different purposes\n",
    "    conditions = [\n",
    "        df['Purpose_Label'].isin([\"Holiday/pleasure\", \"Getting married\", \"Play amateur sport\",\n",
    "                                  \"Watch sport\", \"Personal shopping\", \"Religious Pilgrimage\",\n",
    "                                  \"Cruise 0-2 nights ashore - UK\", \"Olympics/Paralympics Watch\",\n",
    "                                  \"Cruise 0-2 nights ashore - For\"]),\n",
    "        df['Purpose_Label'].isin([\"Business; Work\", \"Visit trade fair\", \"Conference 20+ people\",\n",
    "                                  \"Definite job to go to\", \"Working Holiday\", \n",
    "                                  \"Olympics/Paralympics Participate\", \"Olympics/Paralympics Work\"]),\n",
    "        df['Purpose_Label'].isin([\"Visit family (priority)\", \"Visit friends\"]),\n",
    "        df['Purpose_Label'].isin([\"First/foundation degree\", \"Higher/PostGrad degree\",\n",
    "                                  \"English language course\", \"Course between school and degree\",\n",
    "                                  \"Secondary education\", \"Professional qualification\",\n",
    "                                  \"Other formal study\", \"University Degree or Diploma\",\n",
    "                                  \"Formal course (check residence and definition)\", \"Formal Course\",\n",
    "                                  \"Other Course Below Degree Level & Above Secondary Education\",\n",
    "                                  \"English language course (not degree level)\", \"Au Pair\", \n",
    "                                  \"Medical treatment\", \"Accompany / join\", \"OTHER\",\n",
    "                                  \"Unacc schoolchild (16 or under, school to parents)\", \n",
    "                                  \"Joining another traveller\",\"Accompany another traveller\"]),\n",
    "        df['Purpose_Label'].isin(excluded_purposes),\n",
    "        df['Purpose_Label'].isna(),\n",
    "    ]\n",
    "    #migrants will be filtered out later, but we will keep them for now\n",
    "    #map the different purposes to their new labels\n",
    "    choices = [\"Holiday\", \"Business or Work\", \"VFF\", \"Education and Other\", \"Migrants/In-eligibles\", \"N/A\"]\n",
    "    #create the column\n",
    "    df['Broad_Purpose'] = np.select(conditions, choices, default='N/A')\n",
    "    \n",
    "    \n",
    "#call this function for df_qcontcust of each year\n",
    "dataframes = [df_qcontcust_2009, df_qcontcust_2010, df_qcontcust_2011, df_qcontcust_2012,\n",
    "              df_qcontcust_2013, df_qcontcust_2014, df_qcontcust_2015, df_qcontcust_2016,\n",
    "              df_qcontcust_2017, df_qcontcust_2018, df_qcontcust_2019, df_qcontcust_2022]\n",
    "\n",
    "#iterate over the list of dataframes and apply the function for all years\n",
    "for df in dataframes:\n",
    "    create_broad_purpose_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Broad_Purpose\n",
       "N/A                      192230\n",
       "Holiday                   54945\n",
       "VFF                       27150\n",
       "Business or Work          18057\n",
       "Migrants/In-eligibles      4277\n",
       "Education and Other        2428\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qcontcust_2015['Broad_Purpose'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Broad_Nationality column\n",
    "#define the countries for each broad nationality\n",
    "\n",
    "north_america = [\"Canada\", \"Haiti\", \"Mexico\", \"USA\", \"US Virgin Isles\", \"USA/United States of America\"]  \n",
    "\n",
    "south_and_central_america = [\"Argentina\", \"Bahamas\", \"Barbados\", \"Barbuda/Antigua\", \"Belize\", \"Bolivia\", \"Brazil\", \"Chile\", \n",
    "                             \"Colombia\", \"Costa Rica\", \"El Salvador\", \"Guatemala\", \"Cuba\", \"Dominican Republic\", \n",
    "                             \"Dominica\", \"Ecuador\", \"Guyana\", \"Honduras\", \"Jamaica\", \"Nicaragua\", \"Panama\",\n",
    "                             \"Peru\", \"Paraguay\", \"Puerto Rico\", \"Surinam/Dutch Guiana\", \"Trinidad & Tobago\", \n",
    "                             \"Uruguay\", \"Venezuela\"]\n",
    "\n",
    "\n",
    "uk = [\"UK\", \"UK/United Kingdom\"]\n",
    "\n",
    "eu = [\"Austria\", \"Belgium\", \"Bosnia Herzegovina\", \"Bulgaria\", \"Croatia\", \"Czech Republic\", \"Denmark\",\n",
    "      \"Estonia\", \"Finland\", \"France/Corsica\", \"France\", \"French Guiana\", \"Mayotte\", \"Germany\", \n",
    "      \"Greece/Crete/Rhodes\", \"Greece\", \"Southern (Greek) Cyprus\", \"Hungary\", \"Irish Republic\", \"Ireland\", \"Italy\", \"Italy/Sardinia\", \"Latvia\",\n",
    "      \"Guadeloupe\", \"Lithuania\", \"Luxembourg\", \"Netherlands\", \"Martinique\", \"Malta\", \"Holland\", \"Portugal\", \n",
    "      \"Poland\", \"Madeira/Azores\", \"Reunion Island\", \"Romania\", \"Slovakia\", \"Slovenia\", \"Sweden\", \"Spain\", \n",
    "      \"Spain/Balearic\", \"Canary Islands\"  , \"Portugal/Portucalense/Portugal\", \"Turkish Republic of North Cyprus\"\n",
    "      ]\n",
    "\n",
    "non_eu_europe = [\"Albania\", \"Andorra\", \"Azerbaijan\", \"Armenia\", \"Belarus\", \"Aland Islands\", \"Georgia\", \n",
    "                 \"Gibraltar\", \"Vatican\", \"Iceland\", \"Liechtenstein\", \"Monaco\", \"Moldova\", \"Montenegro\",\n",
    "                 \"Norway\", \"Serbia\", \"Switzerland\", \"Macedonia\", \"North Cyprus\", \"South Cyprus\", \"Kosova\"]\n",
    "\n",
    "\n",
    "africa = [\"Algeria\", \"Angola\", \"Botswana\", \"Burundi\", \"Cameroon\", \"Cape Verde Islands\", \"Central African Rep\",\n",
    "          \"Chad\", \"Comoros\", \"Congo (Brazzaville)\", \"Democratic Republic of Congo\", \"Benin\", \"South Sudan\",\n",
    "          \"Equatorial Guinea\", \"Ethiopia\", \"South Sudan\", \"Eritrea\", \"Djibouti\", \"Gabon\", \"Gambia\", \"Ghana\",\n",
    "          \"Guinea\", \"Ivory Coast\", \"Kenya\", \"Lesotho\", \"Liberia\", \"Libya\", \"Madagascar\", \"Malawi\", \"Mali\",\n",
    "          \"Mauritania\", \"Mauritius\", \"Morocco\", \"Mozambique\", \"Namibia\", \"Niger\", \"Nigeria\", \"Guinea - Bissau\",\n",
    "          \"Rwanda\", \"Sao Tome\", \"Senegal\", \"Seychelles\", \"Sierra Leone\", \"Somalia\", \"South Africa\", \"Zimbabwe\",\n",
    "          \"North Sudan\", \"Swaziland\", \"Togo\", \"Tunisia\", \"Uganda\", \"Egypt\", \"Tanzania\", \"Tanzania/Zanzibar\", \n",
    "          \"Burkina Faso\", \"Zambia\", \"Benin (formerly Dahomey)\"]\n",
    "\n",
    "\n",
    "asia = [\"Afghanistan\", \"Bahrain\", \"Bangladesh\", \"Bhutan\", \"Brunei\", \"Myanmar (Burma)\", \"Cambodia/Kampuchea\", \n",
    "        \"Sri Lanka\", \"China (excl Taiwan)/Tibet\", \"China/Tibet\", \"Cambodia\", \"Taiwan\", \"Palestine\", \"Hong Kong\", \"Hong Kong Special\", \n",
    "        \"India\", \"Bali/Borneo/Indonesia\", \"Indonesia\", \"Iran\", \"Iraq\", \"Israel\", \"Japan\", \"Kazakhstan\", \"Jordan\", \n",
    "        \"North Korea\", \"South Korea\", \"Korea, South Rep\", \"Korea, North\", \"Kuwait\", \"Kyrgyzstan\", \"Laos\", \"Lebanon\", \"Macao\", \"Malaysia\", \"Maldives\",\n",
    "        \"Mongolia\", \"Oman\", \"Nepal\", \"Pakistan\", \"Philippines\", \"East Timor\", \"Qatar\", \"Russia\", \"Saudi Arabia\",\n",
    "        \"Singapore\", \"Vietnam\", \"Syria\", \"Tajikistan\", \"Thailand\", \"Turkey\", \"United Arab Emirates\", \n",
    "        \"Turkmenistan\", \"Ukraine\", \"Uzbekistan\", \"Yemen (North & South)\"]\n",
    "\n",
    "oceania = [\"Australia\", \"Christmas Is/Oceania\", \"Cocos I/Oceania\", \"Cook Is/Oceania\", \"Fiji\", \"Oceania Islands\",\n",
    "           \"Guam\", \"Nauru/Oceania\", \"Vanuatu\", \"New Zealand\", \"Niue Island\", \"Norfolk Island\", \"Micronesia\",\n",
    "           \"Marshall Island\", \"Palau\", \"Papua New Guinea\", \"Wallis & Futuna Islands\", \"Samoa\", \n",
    "           \"Ellice Island/Oceania\", \"Tonga/Oceania\"]\n",
    "\n",
    "\n",
    "other = [\"American Samoa/Oceania\", \"Antartica\", \"Antarctica etc (Foreign)\", \"Antigua\",  \"Bermuda\", \"Bouvet Island\",\n",
    "         \"British Indian Ocean Territory\", \"Solomon Island\", \"Virgin Islands (Br)\", \"Cayman Islands\",\n",
    "         \"Faroe Islands\", \"Falkland Is/British Antarctic\", \"South Georgia/South Sanwich Islands\", \n",
    "         \"French Polynesia/Tahiti\", \"French Sthrn/Antarctic Territories\", \"Greenland\", \"Grenada\",\n",
    "         \"Heard & McDonald Islands\", \"Curacao\", \"Bonaire\", \"St Maarten\", \"Montserrat\", \"Antilles\", \"Aruba\",\n",
    "         \"Netherlands Antilles\", \"New Caledonia\", \"Mariana Island\", \"Pacific Islands\", \"Pitcairn Islands\", \n",
    "         \"St Barthelemy\", \"Ascension Islands/St Helena/Trist\", \"Nevis/St Kitts\", \"Anguilla\", \"St Lucia\",\n",
    "         \"St Martin\", \"St Pierre et Miquelon\", \"Grenadines/St Vincent\", \"San Marino\", \"Turks & Caicos Islands\",\n",
    "         \"British Overseas\", \"Guernsey\", \"Jersey\", \"Isle Of Man\", \"Channel Islands\"] \n",
    "        #carribean countries, british overseas territory included\n",
    "\n",
    "not_disclosed = [\"Country not disclosed\", \"Stateless\", \"Country Not Stated\", \"Short Haul\", \n",
    "                 \"Cruise - Europe/Departures\", \"Cruise - Elsewhere/Departures\", \n",
    "                 \"Cruise - Europe/Arrivals - UK Ship\", \"Cruise - Europe/Arrivals - Foreign Ship\", \n",
    "                 \"Cruise - Europe/Arrivals - DK Ship\", \"Cruise - Elsewhere/Arrivals - UK Ship\", \n",
    "                 \"Cruise - Elsewhere/Arrivals - Foreign Ship\", \"Cruise - Elsewhere/Arrivals - DK Ship\", \n",
    "                 \"Cruise - DK where - Arr & Dep\"]\n",
    "\n",
    "#function to categorize countries\n",
    "def create_broad_nationality_column(country):\n",
    "    \"\"\"\n",
    "    This function creates a new column Broad_Purpose which is derived from the column Purpose_Label.\n",
    "    Broad_Purpose catgorises the different purposes of visit into 4 main categories. These purposes will\n",
    "    be further filtered later in this notebook.\n",
    "    Broad_Purpose is the main variable of interest in this project.\n",
    "\n",
    "    Parameters:\n",
    "    param1 : the dataframe being manipulated.\n",
    "\n",
    "    Returns:\n",
    "    string: The broad nationality that the country belongs to.\n",
    "    \"\"\"\n",
    "    \n",
    "    if country in north_america:\n",
    "        return \"North America\"\n",
    "    elif country in south_and_central_america:\n",
    "        return \"South America\"\n",
    "    elif country in eu:\n",
    "        return \"EU\"\n",
    "    elif country in uk:\n",
    "        return \"UK\"\n",
    "    elif country in non_eu_europe:\n",
    "        return \"Non-EU Europe\"\n",
    "    elif country in africa:\n",
    "        return \"Africa\"\n",
    "    elif country in asia:\n",
    "        return \"Asia\"\n",
    "    elif country in oceania:\n",
    "        return \"Australia, NZ and Oceania\"\n",
    "    elif country in other:\n",
    "        return \"Other\"   \n",
    "    else:\n",
    "        return \"Not disclosed\"\n",
    "\n",
    "#call this function for df_qcontcust of each year\n",
    "dataframes = [df_qcontcust_2009, df_qcontcust_2010, df_qcontcust_2011, df_qcontcust_2012,\n",
    "              df_qcontcust_2013, df_qcontcust_2014, df_qcontcust_2015, df_qcontcust_2016,\n",
    "              df_qcontcust_2017, df_qcontcust_2018, df_qcontcust_2019, df_qcontcust_2022]\n",
    "\n",
    "#iterate over the list of dataframes and apply the function for all years\n",
    "for df in dataframes:\n",
    "    df['Broad_Nationality'] = df['Nationality_Label'].apply(create_broad_nationality_column)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Broad_Nationality\n",
       "UK                           116349\n",
       "EU                            54189\n",
       "Asia                          19726\n",
       "North America                 15671\n",
       "Australia, NZ and Oceania      3353\n",
       "Africa                         2951\n",
       "Non-EU Europe                  2803\n",
       "South America                  1886\n",
       "Not disclosed                   800\n",
       "Other                           119\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qcontcust_2019['Broad_Nationality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Serial', 'Year', 'Quarter', 'Month', 'Flow', 'res', 'cty', 'nation',\n",
       "       'purp', 'Purpose', 'county', 'Age', 'Sex', 'ukport', 'Nationality',\n",
       "       'Residence', 'CountryVisit', 'country', 'port1', 'port2', 'AirPortCode',\n",
       "       'ChangeCode', 'origdest', 'carrier1', 'transfer', 'flightyp', 'Vehicle',\n",
       "       'vehno', 'persons', 'Fare', 'expppv', 'NetExp', 'shift', 'Quality',\n",
       "       'Stay', 'Spend', 'FinalWeight', 'IntDate', 'Flow_Label',\n",
       "       'Purpose_Label', 'Nationality_Label', 'Stay_Category', 'Spend_Category',\n",
       "       'Broad_Purpose', 'Broad_Nationality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qcontcust_2022.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing this for years 2009 - 2019\n",
    "years = list(range(2009, 2020))\n",
    "years.append(2022)\n",
    "\n",
    "dataframes = [df_qcontcust_2009, df_qcontcust_2010, df_qcontcust_2011, df_qcontcust_2012,\n",
    "              df_qcontcust_2013, df_qcontcust_2014, df_qcontcust_2015, df_qcontcust_2016,\n",
    "              df_qcontcust_2017, df_qcontcust_2018, df_qcontcust_2019, df_qcontcust_2022]\n",
    "\n",
    "for year, df in zip(years, dataframes):\n",
    "    filtered_df = df[df['Year'] == year]\n",
    "\n",
    "#iterate over the list of dataframes for each year and apply flitering\n",
    "for year, df in zip(years, dataframes):\n",
    "    #filtering for the specific year\n",
    "    filtered_df = df[df['Year'] == year]\n",
    "    \n",
    "    #considering only foreign departures and UK Arrivals (sea and air)\n",
    "    filtered_df = filtered_df[(filtered_df['Flow'].isin([1,4,5,8]))]\n",
    "    \n",
    "    #exclude specific purposes like military, same day transit, migrants\n",
    "    filtered_df = filtered_df[~filtered_df['Purpose'].isin([23,24,25,50,51,52,80,81,82,83,84,97,98])]\n",
    "    \n",
    "    #exclude same day transit for UK arrivals \n",
    "    filtered_df = filtered_df[~((filtered_df['Purpose'] == 71) & (filtered_df['Flow'].isin([4, 8])))]\n",
    "    \n",
    "    #filtering out Channel Islands and Isle of Man records for nationality\n",
    "    #also removing stateless, not disclosed, unknown\n",
    "    filtered_df = filtered_df[~((filtered_df['Nationality'].isin([830,831,832,833,931,958,9999,0])) & ~(filtered_df['Serial'].between(999900001001,999900005013)))]\n",
    "    \n",
    "    #further considering only foreign departures\n",
    "    foreign_dep_df = filtered_df[(filtered_df['Flow'].isin([1,5]))] \n",
    "    \n",
    "    #removing cases with internal trips to Channel Islands and Isle of Man\n",
    "    foreign_dep_df = foreign_dep_df[~(foreign_dep_df['AirPortCode'].isin(['831002', '832001', '833004', '931003']))] \n",
    "    foreign_dep_df = foreign_dep_df[~(foreign_dep_df['ChangeCode'].isin(['831002', '832001', '833004', '931003'])) | (pd.isna(foreign_dep_df['ChangeCode']))] \n",
    "    foreign_dep_df.dropna(subset=['Broad_Purpose'], inplace=True)\n",
    "    \n",
    "    #remove records where 'Age' is 0, 1, 9, or -1\n",
    "    #removing unknowns, children under 16, missing values\n",
    "    foreign_dep_df['Age'].replace(' ', -1, inplace=True)\n",
    "    foreign_dep_df['Age'] = foreign_dep_df['Age'].astype(int)\n",
    "    foreign_dep_df = foreign_dep_df[~foreign_dep_df['Age'].isin([0, 1, 9, -1])]\n",
    "    \n",
    "    #dynamically create variables for the filtered dataframes for each year\n",
    "    #each year now has a corresponding foreign_dep_20xx\n",
    "    globals()[f'foreign_dep_{year}'] = foreign_dep_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow_Label\n",
      "Air Departure Foreign    38263\n",
      "Sea Departure Foreign     6229\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age\n",
       "5    7342\n",
       "6    7016\n",
       "4    6682\n",
       "7    4750\n",
       "2    3046\n",
       "8    2807\n",
       "3     491\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(foreign_dep_2022['Flow_Label'].value_counts())\n",
    "foreign_dep_2018['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Month', 'Quarter', 'Flow', 'Serial', 'town1', 'stay1',\n",
       "       'accom1', 'STAY1K', 'SPEND1', 'town2', 'stay2', 'accom2', 'STAY2K',\n",
       "       'SPEND2', 'town3', 'stay3', 'accom3', 'STAY3K', 'SPEND3', 'town4',\n",
       "       'stay4', 'accom4', 'STAY4K', 'SPEND4', 'town5', 'stay5', 'accom5',\n",
       "       'STAY5K', 'SPEND5', 'town6', 'stay6', 'accom6', 'STAY6K', 'SPEND6',\n",
       "       'town7', 'stay7', 'accom7', 'STAY7K', 'SPEND7', 'town8', 'stay8',\n",
       "       'accom8', 'STAY8K', 'SPEND8', 'town9', 'stay9', 'accom9', 'STAY9K',\n",
       "       'SPEND9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let us look at the qreg datasets\n",
    "\n",
    "df_qreg_2022.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping these columns as they contain mostly null values\n",
    "\n",
    "columns_to_drop = ['town4', 'stay4', 'accom4', 'STAY4K', 'spend4', \n",
    "                   'town5', 'stay5', 'accom5', 'STAY5K', 'spend5', \n",
    "                   'town6', 'stay6', 'accom6', 'STAY6K', 'spend6', \n",
    "                   'town7', 'stay7', 'accom7', 'STAY7K', 'spend7', \n",
    "                   'town8', 'stay8', 'accom8', 'STAY8K', 'spend8']\n",
    "\n",
    "dataframes = [df_qreg_2013, df_qreg_2014, df_qreg_2015, df_qreg_2016, \n",
    "              df_qreg_2017, df_qreg_2018, df_qreg_2019]\n",
    "\n",
    "for df in dataframes:\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "  \n",
    "#different year's data have different column names  \n",
    "cols_to_drop = ['town9', 'stay9', 'accom9', 'STAY9K', 'spend9']   \n",
    "dataframes = [df_qreg_2016, df_qreg_2017, df_qreg_2018, df_qreg_2019] \n",
    "\n",
    "for df in dataframes:\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "columns_to_drop = ['town4', 'stay4', 'accom4', 'STAY4K', 'SPEND4', \n",
    "                   'town5', 'stay5', 'accom5', 'STAY5K', 'SPEND5', \n",
    "                   'town6', 'stay6', 'accom6', 'STAY6K', 'SPEND6',\n",
    "                   'town7', 'stay7', 'accom7', 'STAY7K', 'SPEND7', \n",
    "                   'town8', 'stay8', 'accom8', 'STAY8K', 'SPEND8', \n",
    "                   'town9', 'stay9', 'accom9', 'STAY9K', 'SPEND9']\n",
    "df_qreg_2022.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Month', 'Quarter', 'Flow', 'Serial', 'town1', 'stay1',\n",
       "       'accom1', 'STAY1K', 'spend1', 'town2', 'stay2', 'accom2', 'STAY2K',\n",
       "       'spend2', 'town3', 'stay3', 'accom3', 'STAY3K', 'spend3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qreg_2018.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging foreign_dep_20xx with corresponding columns of df_qreg_20xx\n",
    "#df_qreg_20xx contains only foreign departures\n",
    "#a left join keeps only the common records\n",
    "\n",
    "for year in range(2013, 2020):\n",
    "    foreign_dep_year = globals()[f'foreign_dep_{year}']\n",
    "    df_qreg_year = globals()[f'df_qreg_{year}']\n",
    "    merged_df_year = pd.merge(foreign_dep_year, df_qreg_year, on='Serial', how='left')\n",
    "    #a left join keeps only the common records\n",
    "    #a left join returns all rows from foreign_dep_20xx and any rows with matching keys \n",
    "    #from the df_qreg_20xx. The key here is the column Serial.\n",
    "    globals()[f'merged_df_{year}'] = merged_df_year\n",
    "\n",
    "# For the year 2022\n",
    "foreign_dep_2022 = globals()['foreign_dep_2022']\n",
    "df_qreg_2022 = globals()['df_qreg_2022']\n",
    "merged_df_2022 = pd.merge(foreign_dep_2022, df_qreg_2022, on='Serial', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Serial', 'Year_x', 'Quarter_x', 'Month_x', 'Flow_x', 'res', 'cty',\n",
       "       'nation', 'purp', 'Purpose', 'county', 'Age', 'Sex', 'ukport',\n",
       "       'Nationality', 'Residence', 'CountryVisit', 'country', 'port1', 'port2',\n",
       "       'AirPortCode', 'ChangeCode', 'origdest', 'carrier1', 'transfer',\n",
       "       'flightyp', 'Vehicle', 'vehno', 'persons', 'expppv', 'netexp', 'shift',\n",
       "       'quality', 'stay', 'spend', 'spendk', 'FinalWeight', 'DayOfWeek',\n",
       "       'Flow_Label', 'Purpose_Label', 'Nationality_Label', 'Stay_Category',\n",
       "       'Spend_Category', 'Broad_Purpose', 'Broad_Nationality', 'Year_y',\n",
       "       'Month_y', 'Quarter_y', 'Flow_y', 'town1', 'stay1', 'accom1', 'STAY1K',\n",
       "       'spend1', 'town2', 'stay2', 'accom2', 'STAY2K', 'spend2', 'town3',\n",
       "       'stay3', 'accom3', 'STAY3K', 'spend3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_2016.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicate columns\n",
    "\n",
    "cols_drop = ['Year_y', 'Month_y', 'Quarter_y', 'Flow_y']\n",
    "\n",
    "dataframes = [merged_df_2013, merged_df_2014, merged_df_2015,merged_df_2016, \n",
    "              merged_df_2017, merged_df_2018, merged_df_2019, merged_df_2022]\n",
    "\n",
    "for df in dataframes:\n",
    "    df.drop(columns=cols_drop, inplace=True)\n",
    "    df.rename(columns={'Year_x': 'Year', 'Quarter_x': 'Quarter', 'Month_x': 'Month', 'Flow_x': 'Flow'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Serial', 'Year', 'Quarter', 'Month', 'Flow', 'res', 'cty', 'nation',\n",
       "       'purp', 'Purpose', 'county', 'Age', 'Sex', 'ukport', 'Nationality',\n",
       "       'Residence', 'CountryVisit', 'country', 'port1', 'port2', 'AirPortCode',\n",
       "       'ChangeCode', 'origdest', 'carrier1', 'transfer', 'flightyp', 'Vehicle',\n",
       "       'vehno', 'persons', 'expppv', 'netexp', 'shift', 'quality', 'stay',\n",
       "       'spend', 'spendk', 'FinalWeight', 'DayOfWeek', 'Flow_Label',\n",
       "       'Purpose_Label', 'Nationality_Label', 'Stay_Category', 'Spend_Category',\n",
       "       'Broad_Purpose', 'Broad_Nationality', 'town1', 'stay1', 'accom1',\n",
       "       'STAY1K', 'spend1', 'town2', 'stay2', 'accom2', 'STAY2K', 'spend2',\n",
       "       'town3', 'stay3', 'accom3', 'STAY3K', 'spend3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_2014.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df_2019['town1'].replace(' ', np.nan, inplace=True)\n",
    "\n",
    "\n",
    "merged_df_2019 = merged_df_2019.dropna(subset=['town1'])\n",
    "merged_df_2019['town1'].astype(float)\n",
    "\n",
    "london_codes = [70700, 77777.0, 70700.0, 72000, 70100.0, 71200.0, 71300.0, 72800, 70900.0, 70800.0, \n",
    "                71100.0, 70600.0, 72200.0, 72100.0]\n",
    "\n",
    "#set initial values to 0\n",
    "merged_df_2019['London_or_out'] = 0\n",
    "#mark rows where town1 is in the specified values with 1\n",
    "merged_df_2019.loc[merged_df_2019['town1'].astype(int).isin(london_codes), 'London_or_out'] = 1\n",
    "\n",
    "merged_df_2019['London_or_out'] = merged_df_2019['London_or_out'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion to create a new column London_or_out which catgorises the towns visited by the \n",
    "# passenger into London or outside London  \n",
    "\n",
    "\n",
    "def create_london_or_out_column(df):\n",
    "    #replace empty strings with NaN\n",
    "    df['town1'].replace(' ', np.nan, inplace=True)\n",
    "    \n",
    "    #specify London codes\n",
    "    # 70700: London, 77777.0: London, 70700.0: City of London/Westminster, 72000: Kensington & Chelsea, \n",
    "    # 70100.0: Barking & Dagenham, 71200.0: Hackney, 71300.0: Hammersmith & Fulham, 72800: Southwark, \n",
    "    # 70900.0: Ealing, 70800.0: Croydon, 71100.0: Greenwich, 70600.0: Camden, 72200.0: Lambeth, \n",
    "    # 72100.0: Kingston upon Thames\n",
    "    # 601: Manchester, 50504: Edinburgh\n",
    "    \n",
    "    london_codes = [70700, 77777.0, 70700.0, 72000, 70100.0, 71200.0, 71300.0, 72800, 70900.0, 70800.0, \n",
    "                    71100.0, 70600.0, 72200.0, 72100.0]\n",
    "    \n",
    "   #drop rows with NaN values \n",
    "    df['town1'] = df['town1'].astype(float)\n",
    "    df.dropna(subset=['town1'], inplace=True)\n",
    "    \n",
    "    #initialize London_or_out column with 0\n",
    "    df['London_or_out'] = 0\n",
    "    #mark rows where town1 is London with 1\n",
    "    df.loc[df['town1'].isin(london_codes), 'London_or_out'] = 1\n",
    "    df['London_or_out'] = df['London_or_out'].astype(int)\n",
    "    \n",
    "    return df\n",
    "#apply the function to all years\n",
    "dataframes = [merged_df_2013, merged_df_2014, merged_df_2015, merged_df_2016,\n",
    "              merged_df_2017, merged_df_2018, merged_df_2019, merged_df_2022]\n",
    "\n",
    "\n",
    "#iterate over the list of dataframes and apply the function for all years\n",
    "for i, df in enumerate(dataframes):\n",
    "    dataframes[i] = create_london_or_out_column(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "London_or_out\n",
       "0    17808\n",
       "1     9599\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_2019['London_or_out'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
